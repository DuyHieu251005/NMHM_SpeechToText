\section{Tổng quan dữ liệu đầu vào}

\subsection{Giới thiệu bộ dữ liệu VIVOS}

\begin{itemize}
    \item \textbf{Tổng số giờ audio}: 15 giờ
    \item \textbf{Tần số lấy mẫu}: 16,000 Hz (16 kHz)
    \item \textbf{Định dạng file}: WAV
    \item \textbf{Ngôn ngữ}: Tiếng Việt (giọng miền Nam - Southern Vietnamese)
    \item \textbf{Môi trường ghi âm}: Phòng yên tĩnh với microphone chất lượng cao
    \item \textbf{Nội dung}: Người đọc đọc từng dòng văn bản đã chuẩn bị sẵn
    \item Mô hình \texttt{nguyenvulebinh/wav2vec2-base-vietnamese-250h} sau đó được fine-tune trên VIVOS trong nghiên cứu này.
    \item Mô hình \texttt{vinai/PhoWhisper-small} được VinAI pretrain trên lượng dữ liệu tiếng Việt lớn, sau đó được fine-tune trên VIVOS.
    \item Mô hình \texttt{openai/whisper-tiny} được OpenAI pretrain trên lượng dữ liệu đa ngôn ngữ lớn, sau đó được fine-tune trên VIVOS.
    \item Việc sử dụng pretrained models giúp tận dụng kiến thức đã học từ dữ liệu lớn, chỉ cần fine-tune trên VIVOS 15 giờ để đạt hiệu quả cao.
\end{itemize}

\subsection{Tỷ lệ chia dữ liệu}

Bộ dữ liệu VIVOS đã được chia sẵn thành hai tập: \texttt{train} và \texttt{test}. Tỷ lệ chia cụ thể như sau:

\begin{table}[h!]
\centering
\caption{Phân chia dữ liệu VIVOS}
\begin{tabular}{|l|c|c|}
\hline
\textbf{Tập dữ liệu} & \textbf{Số lượng mẫu} & \textbf{Tỷ lệ (\%)} \\
\hline
Training (Train) & 11,660 & 93.88\% \\
\hline
Testing (Test) & 760 & 6.12\% \\
\hline
\textbf{Tổng cộng} & \textbf{12,420} & \textbf{100\%} \\
\hline
\end{tabular}
\label{tab:data_split}
\end{table}

\textbf{Lưu ý về Validation Set}: Trong quá trình fine-tuning PhoWhisper, 200 mẫu từ tập Test được sử dụng làm validation để theo dõi quá trình huấn luyện.

\textbf{Lý do chọn tỷ lệ này:}
\begin{enumerate}
    \item \textbf{Sử dụng tỷ lệ có sẵn của VIVOS}: Bộ dữ liệu VIVOS đã được các nhà phát triển chia sẵn theo tỷ lệ $\approx$ 94/6 (train/test). Việc giữ nguyên cách chia này đảm bảo tính nhất quán với các nghiên cứu trước đó sử dụng cùng bộ dữ liệu.
    
    \item \textbf{Tối đa hóa dữ liệu huấn luyện}: Với tổng số 12,420 mẫu, việc dành phần lớn dữ liệu (93.88\%) cho huấn luyện giúp mô hình học được nhiều biến thể ngôn ngữ và giọng nói hơn.
    
    \item \textbf{Tập Test đủ lớn để đánh giá}: 760 mẫu test đủ để đánh giá hiệu năng mô hình một cách đáng tin cậy, bao gồm nhiều speaker và nội dung khác nhau.
\end{enumerate}

\subsection{Tiền xử lý}

\textbf{Xử lý Audio:}

\begin{enumerate}
    \item \textbf{Tải file âm thanh}: Đọc file WAV từ thư mục \texttt{waves/} theo cấu trúc \texttt{waves/SPEAKER\_ID/FILE\_ID.wav}.
    
    \item \textbf{Resampling}: Chuyển đổi tần số lấy mẫu về 16,000 Hz (16 kHz) - là tần số của vivos
    
    \item \textbf{Feature Extraction}:
    \begin{itemize}
        \item \textbf{PhoWhisper và Whisper-tiny}: Chuyển đổi audio thành Log-Mel Spectrogram bằng \texttt{WhisperProcessor.feature\_extractor()}. Spectrogram này là biểu diễn 2D của tín hiệu âm thanh theo thời gian và tần số.
        \item \textbf{Wav2Vec2}: Sử dụng \texttt{Wav2Vec2FeatureExtractor} để chuẩn hóa waveform thành \texttt{input\_values} với padding phù hợp.
    \end{itemize}
\end{enumerate}

\textbf{Xử lý Text (Nhãn):}
\begin{enumerate}
    \item \textbf{Đọc transcript}: Tải nội dung văn bản từ file \texttt{prompts.txt}, mỗi dòng có định dạng: \texttt{FILE\_ID câu\_văn\_bản}.
    
    \item \textbf{Normalization}: Chuẩn hóa văn bản về chữ thường (lowercase) tiếng Việt:
    \begin{verbatim}
    ref_norm = text.lower().strip()
    pred_norm = transcription.lower().strip()
    \end{verbatim}
    
    \item \textbf{Tokenization}:
    \begin{itemize}
        \item \textbf{PhoWhisper và Whisper-tiny}: Sử dụng \texttt{WhisperProcessor.tokenizer()} để chuyển văn bản thành chuỗi token IDs, lưu vào trường \texttt{labels}.
        \item \textbf{Wav2Vec2}: Sử dụng \texttt{Wav2Vec2CTCTokenizer} với các token đặc biệt: \texttt{[UNK]} (unknown), \texttt{[PAD]} (padding), và \texttt{|} (word delimiter).
    \end{itemize}
\end{enumerate}

\textbf{Data Collation:}
Trong quá trình huấn luyện, các batch dữ liệu được xử lý bởi Data Collator:



%% verified by code
\begin{itemize}
    \item \textbf{Padding}: Các input features và labels được pad về cùng độ dài trong mỗi batch.
    \item \textbf{Masking}: Padding tokens trong labels được thay bằng giá trị \texttt{-100} để không tính vào hàm loss:
    \begin{verbatim}
    labels = labels.masked_fill(attention_mask.ne(1), -100)
    \end{verbatim}
    \item \textbf{Loại bỏ BOS token}: Token bắt đầu câu (BOS - Beginning of Sentence) được loại bỏ khỏi labels nếu có.
\end{itemize} 